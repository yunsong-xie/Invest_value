{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, os, sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import urllib.request\n",
    "from termcolor import colored\n",
    "import glob, xlrd\n",
    "\n",
    "\n",
    "def search_1st_col(sheet, keyword, strict=True):\n",
    "    n_search = 100\n",
    "    row_keyword = -1\n",
    "    try:\n",
    "        for i in range(n_search):\n",
    "            if strict:\n",
    "                if keyword == (sheet.cell(i, 0).value.split('\\n')[0]):\n",
    "                    row_keyword = i\n",
    "                    return row_keyword\n",
    "            else:\n",
    "                if keyword in (sheet.cell(i, 0).value.split('\\n')[0]):\n",
    "                    row_keyword = i\n",
    "                    return row_keyword\n",
    "    except:\n",
    "        return row_keyword\n",
    "    return row_keyword\n",
    "\n",
    "\n",
    "def get_dict_symbol(workbook):\n",
    "    sheet_HC = workbook.sheet_by_name('Historical Capitalization')\n",
    "    HC_symbol = search_1st_col(sheet_HC, 'Financials', strict=False)\n",
    "    exchange_ticker = re.findall('[A-Za-z]*:[A-Z]*', sheet_HC.cell(HC_symbol, 0).value)[0]\n",
    "    exchange, symbol = exchange_ticker.split(':')\n",
    "    dict_symbol = {'symbol': symbol, 'exchange': exchange, 'exchange_ticker': exchange_ticker}\n",
    "    return dict_symbol\n",
    "\n",
    "\n",
    "def get_row_value(pd_sum_input, workbook, sheet_id='Historical Capitalization', item_id='Share Price', time_list=[]):\n",
    "    \"\"\"\n",
    "    This function output pd dataframe there are two cases:\n",
    "    1. time_list == []: time_list initiation, query \"Share Price\" row, get the time_list that has available share Price\n",
    "    2. time_list != []: Get the row with given name \"Net Income\", \"Revenue\", etc. Only select the entries\n",
    "                        that is within the \"time_list\" input\n",
    "    :param pd_sum_input:    Current available pd_sum\n",
    "    :param workbook:    XLRD Workbook\n",
    "    :param sheet_id:    sheet_id or sheet_name\n",
    "    :param item_id:     row name\n",
    "    :param time_list:   time_list\n",
    "    :return:    if time_list is []: pd_sum_output, time_list\n",
    "                if time_list is not []: pd_sum_output\n",
    "    example:\n",
    "    pd_sum_output, time_list = get_row_value(pd_sum, workbook)\n",
    "    pd_sum_output, time_list = get_row_value(pd_sum, workbook, sheet_id, item_id='Share Price', time_list=[])\n",
    "    pd_sum_output = get_row_value(pd_sum, workbook, sheet_id='Income Statement', item_id='Revenue', ['Dec-31-2019'])\n",
    "    \"\"\"\n",
    "    if len(time_list) == 0:\n",
    "        label_base = 1\n",
    "        sheet_id = 'Historical Capitalization'\n",
    "        item_id = 'Share Price'\n",
    "    else:\n",
    "        label_base = 0\n",
    "\n",
    "    sheet_HC = workbook.sheet_by_name(sheet_id)\n",
    "    dict_sum = {'sheet_id': [], 'item_id': [], 'value': [], 'time': []}\n",
    "    time_row_ind = search_1st_col(sheet_HC, dict_time_name[sheet_id])\n",
    "    value_list_ori = sheet_HC.row_values(time_row_ind)\n",
    "    pattern = '[A-Za-z]*-[0-9]*-[0-9]*'\n",
    "    time_list_temp = [re.search(pattern, i) for i in value_list_ori]\n",
    "\n",
    "    item_row_num = search_1st_col(sheet_HC, item_id)\n",
    "    if item_row_num != -1:\n",
    "        # The row does exist\n",
    "        HC_share_price = sheet_HC.row_values(search_1st_col(sheet_HC, item_id))\n",
    "        if label_base == 1:\n",
    "            # Base data query, query \"Share Price\" for time_list initiation\n",
    "            dict_time = {i: time_list_temp[i].group()\n",
    "                         for i in range(len(time_list_temp)) if not (time_list_temp[i] is None)}\n",
    "            dict_share_price = {i: HC_share_price[i] for i in range(len(HC_share_price))\n",
    "                                if not (type(HC_share_price[i]) is str)}\n",
    "        else:\n",
    "            # There is input for time_list query the entries that is within \"time_list\"\n",
    "            dict_time = {i: time_list_temp[i].group()\n",
    "                         for i in range(len(time_list_temp)) if not (time_list_temp[i] is None)}\n",
    "            dict_time = {i: dict_time[i] for i in dict_time if dict_time[i] in time_list}\n",
    "            dict_share_price = {i: HC_share_price[i] for i in dict_time}\n",
    "    else:\n",
    "        # The row does not exist\n",
    "        dict_time = []\n",
    "        dict_share_price = {}\n",
    "\n",
    "    time_list = [dict_time[i] for i in list(dict_share_price.keys())]\n",
    "    for i in list(dict_share_price.keys()):\n",
    "        dict_sum['sheet_id'].append(sheet_id)\n",
    "        dict_sum['item_id'].append(item_id.strip())\n",
    "        dict_sum['value'].append(dict_share_price[i])\n",
    "        dict_sum['time'].append(dict_time[i])\n",
    "\n",
    "    pd_sum_output = pd.concat([pd_sum_input, pd.DataFrame(dict_sum)])\n",
    "\n",
    "    if label_base == 1:\n",
    "        return pd_sum_output, time_list\n",
    "    else:\n",
    "        return pd_sum_output\n",
    "\n",
    "\n",
    "dict_time_name = {'Income Statement': 'For the Fiscal Period Ending',\n",
    "                  'Balance Sheet': 'Balance Sheet as of:',\n",
    "                  'Cash Flow': 'For the Fiscal Period Ending',\n",
    "                  'Historical Capitalization': 'Balance Sheet as of:',\n",
    "                  'Ratios': 'For the Fiscal Period Ending',\n",
    "                  'Segments': 'For the Fiscal Period Ending', }\n",
    "\n",
    "parse_data = [['Income Statement', '  Total Revenue'],\n",
    "              ['Income Statement', '  Operating Income'],\n",
    "              ['Balance Sheet', 'Long-Term Debt'],\n",
    "              ['Balance Sheet', 'Long-Term Leases'],\n",
    "              ['Cash Flow', 'Net Income'],\n",
    "              ['Cash Flow', '  Cash from Ops.'],\n",
    "              ['Income Statement', 'Total Assets'],\n",
    "              ['Balance Sheet', '  Total Current Assets'],\n",
    "              ['Balance Sheet', '  Total Current Liabilities'],\n",
    "              ['Balance Sheet', '  Total Equity'],\n",
    "              ['Income Statement', 'Revenue'],\n",
    "              ['Balance Sheet', 'Retained Earnings'],\n",
    "              ['Income Statement', 'EBIT'],\n",
    "              ['Historical Capitalization', 'Market Capitalization'],\n",
    "              ['Balance Sheet', 'Total Liabilities'],\n",
    "              ['Balance Sheet', 'Accounts Receivable'],\n",
    "              ['Income Statement', '  Gross Profit'],\n",
    "              ['Balance Sheet', '  Net Property, Plant & Equipment'],\n",
    "              ['Balance Sheet', 'Accumulated Depreciation'],\n",
    "              ['Income Statement', 'Selling General & Admin Exp.'],\n",
    "              ['Income Statement', 'Other Operating Expense'],\n",
    "              ['Cash Flow', 'Depreciation & Amort., Total'],\n",
    "              ['Income Statement', 'EBITDA'],\n",
    "              ['Income Statement', 'Diluted EPS'],\n",
    "              ['Balance Sheet', '  Total Cash & ST Investments'],\n",
    "              ]\n",
    "\n",
    "class MyFilter(object):\n",
    "    def __init__(self, mylogfile=sys.stdout):\n",
    "        self.f = mylogfile\n",
    "    def write(self, data):\n",
    "        if \"WARNING *** OLE2 inconsistency\" not in data:\n",
    "            self.f.write(data)\n",
    "log = open(\"the_log_file.txt\", \"w\")\n",
    "log_filter = MyFilter(log)\n",
    "\n",
    "#dir_path = os.path.dirname(os.path.realpath(__file__))\n",
    "#os.chdir(dir_path)\n",
    "\n",
    "folder_path='D:\\PycharmProjects\\Invest_value\\Financial_reports'\n",
    "\n",
    "path_pd_ciq_id='./static/csv/stock_list/pd_ciq_id.pickle'\n",
    "path_parsed_result='./static/csv/stock_list/pd_sum.pickle'\n",
    "pd_ciq_id=pd.read_pickle(path_pd_ciq_id)\n",
    "pd_ciq_id_company=pd_ciq_id.loc[pd_ciq_id.company_type=='company'].copy()\n",
    "pd_ciq_id_company['file_keyword']=pd_ciq_id_company['exchange_ticker'].str.replace(':', ' ')\n",
    "file_keyword_company_list=list(pd_ciq_id_company['file_keyword'])\n",
    "\n",
    "pd_sum_list=[]\n",
    "\n",
    "file_keyword_company_list=file_keyword_company_list\n",
    "\n",
    "count_file=0\n",
    "time_start=time.time()\n",
    "\n",
    "file_keyword_company_list=['NasdaqGS ZION']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for file_keyword_company in file_keyword_company_list:\n",
    "    filename = glob.glob(folder_path + '\\* '+file_keyword_company+' *.xls')\n",
    "    if len(filename)==0:\n",
    "        continue\n",
    "    else:\n",
    "        filename = filename[0]\n",
    "\n",
    "    count_file+=1\n",
    "    workbook=xlrd.open_workbook(filename, logfile=log_filter)\n",
    "\n",
    "    sheetname_list=workbook.sheet_names()\n",
    "\n",
    "    pd_sum_symbol=pd.DataFrame({'sheet_id':[], 'item_id':[], 'value':[], 'time':[]})\n",
    "\n",
    "    try:\n",
    "        pd_sum_symbol, time_list=get_row_value(pd_sum_symbol, workbook)\n",
    "\n",
    "\n",
    "        for parse_data_entry in  parse_data:\n",
    "            sheet_id_entry, item_id_entry = parse_data_entry\n",
    "            pd_sum_symbol=get_row_value(pd_sum_symbol, workbook, sheet_id = sheet_id_entry,\n",
    "                                        item_id=item_id_entry, time_list=time_list)\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "    dict_symbol=get_dict_symbol(workbook)\n",
    "    for key in dict_symbol:\n",
    "        pd_sum_symbol[key] = dict_symbol[key]\n",
    "\n",
    "    workbook.release_resources()\n",
    "    pd_sum_list.append(pd_sum_symbol)\n",
    "    time_span=round(time.time()-time_start, 1)\n",
    "    print('\\rTime: '+str(time_span)+' - Complete parse file '+str(count_file)+'/'+str(len(file_keyword_company_list)), end='')\n",
    "\n",
    "log.close()\n",
    "pd_sum=pd.concat(pd_sum_list)\n",
    "\n",
    "pd_sum.to_pickle(path_parsed_result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
